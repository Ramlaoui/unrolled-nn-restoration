{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "try:\n",
    "    if changed:\n",
    "        raise Exception(\"changed\")\n",
    "except NameError:\n",
    "    changed = False\n",
    "    sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data.generate_synthetic_data import generate_synthetic_sparse_signal, generate_kernel_h\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "# parameters of signal \n",
    "length = 2000\n",
    "sparsity = [0.05, 0.1, 0.2]\n",
    "easy_noise_level = [0.5, 1, 5]\n",
    "easy_kernel_types = [\"identity\", \"deriv\", \"gaussian\", \"sparse_random\",]\n",
    "\n",
    "# number of samples to generate for each parameter combination\n",
    "num_samples = 100\n",
    "\n",
    "# parametes combinations\n",
    "easy_parameters = [(s, n, k) for s in sparsity for n in easy_noise_level for k in easy_kernel_types]\n",
    "print(len(easy_parameters))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "# hard parameters\n",
    "sparsity = [0.05, 0.1, 0.2]\n",
    "hard_noise_level = [0.5, 1, 5, 10, 15]\n",
    "hard_kernel_types = [\"identity\", \"deriv\", \"gaussian\", \"sparse_random\", \"gaussian_heteroscedastic\", \"hard_sparse_random\"]\n",
    "\n",
    "# number of samples to generate for each parameter combination\n",
    "num_samples = 20\n",
    "\n",
    "# parametes combinations\n",
    "hard_parameters = [(s, n, k) for s in sparsity for n in hard_noise_level for k in hard_kernel_types]\n",
    "print(len(hard_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "datasetRoot_easy = os.path.join(\"../data\", \"synthetic_easy\")\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(datasetRoot_easy)\n",
    "except:\n",
    "    pass\n",
    "os.makedirs(datasetRoot_easy)\n",
    "\n",
    "# Create training, validation and test folders\n",
    "# Training\n",
    "training_path = os.path.join(datasetRoot_easy, \"training\")\n",
    "os.makedirs(training_path)\n",
    "training_path_Groundtruth = os.path.join(training_path, \"Groundtruth\")\n",
    "os.makedirs(training_path_Groundtruth)\n",
    "training_path_Degraded2000 = os.path.join(training_path, \"Degraded\")\n",
    "os.makedirs(training_path_Degraded2000)\n",
    "training_path_H = os.path.join(training_path, \"H\")\n",
    "os.makedirs(training_path_H)\n",
    "# Validation\n",
    "validation_path = os.path.join(datasetRoot_easy, \"validation\")\n",
    "os.makedirs(validation_path)\n",
    "validation_path_Groundtruth = os.path.join(validation_path, \"Groundtruth\")\n",
    "os.makedirs(validation_path_Groundtruth)\n",
    "validation_path_Degraded2000 = os.path.join(validation_path, \"Degraded\")\n",
    "os.makedirs(validation_path_Degraded2000)\n",
    "validation_path_H = os.path.join(validation_path, \"H\")\n",
    "os.makedirs(validation_path_H)\n",
    "# Test\n",
    "test_path = os.path.join(datasetRoot_easy, \"test\")\n",
    "os.makedirs(test_path)\n",
    "test_path_Groundtruth = os.path.join(test_path, \"Groundtruth\")\n",
    "os.makedirs(test_path_Groundtruth)\n",
    "test_path_Degraded2000 = os.path.join(test_path, \"Degraded\")\n",
    "os.makedirs(test_path_Degraded2000)\n",
    "test_path_H = os.path.join(test_path, \"H\")\n",
    "os.makedirs(test_path_H, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate original_signal, noisy_signal, H for each parameter combination\n",
    "count = 0\n",
    "for s, n, k in easy_parameters:\n",
    "    print(s, n, k)\n",
    "    print(count, \"th out of\", len(easy_parameters) * num_samples)\n",
    "    for i in range(num_samples):\n",
    "        count += 1\n",
    "        if i < num_samples * 0.6:\n",
    "            path = training_path\n",
    "        elif i < num_samples * 0.8:\n",
    "            path = validation_path\n",
    "        else:\n",
    "            path = test_path\n",
    "        h = generate_kernel_h(length=50, type=k)\n",
    "        degraded_signal, signal, H = generate_synthetic_sparse_signal(length=length, sparsity=s, noise_level=n, h=h)\n",
    "        np.save(os.path.join(path, \"Groundtruth\", \"x_Gr_tr_{}_{}_{}_{}.npy\".format(s, n, k, count)), signal)\n",
    "        np.save(os.path.join(path, \"Degraded\", \"x_De_tr_{}_{}_{}_{}.npy\".format(s, n, k, count)), degraded_signal)\n",
    "        np.save(os.path.join(path, \"H\", \"H_tr_{}_{}_{}_{}.npy\".format(s, n, k, count)), H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "datasetRoot_hard = os.path.join(\"../data\", \"synthetic_hard\")\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(datasetRoot_hard)\n",
    "except:\n",
    "    pass\n",
    "os.makedirs(datasetRoot_hard)\n",
    "\n",
    "# Create training, validation and test folders\n",
    "# Training\n",
    "training_path = os.path.join(datasetRoot_hard, \"training\")\n",
    "os.makedirs(training_path)\n",
    "training_path_Groundtruth = os.path.join(training_path, \"Groundtruth\")\n",
    "os.makedirs(training_path_Groundtruth)\n",
    "training_path_Degraded2000 = os.path.join(training_path, \"Degraded\")\n",
    "os.makedirs(training_path_Degraded2000)\n",
    "training_path_H = os.path.join(training_path, \"H\")\n",
    "os.makedirs(training_path_H)\n",
    "# Validation\n",
    "validation_path = os.path.join(datasetRoot_hard, \"validation\")\n",
    "os.makedirs(validation_path)\n",
    "validation_path_Groundtruth = os.path.join(validation_path, \"Groundtruth\")\n",
    "os.makedirs(validation_path_Groundtruth)\n",
    "validation_path_Degraded2000 = os.path.join(validation_path, \"Degraded\")\n",
    "os.makedirs(validation_path_Degraded2000)\n",
    "validation_path_H = os.path.join(validation_path, \"H\")\n",
    "os.makedirs(validation_path_H)\n",
    "# Test\n",
    "test_path = os.path.join(datasetRoot_hard, \"test\")\n",
    "os.makedirs(test_path)\n",
    "test_path_Groundtruth = os.path.join(test_path, \"Groundtruth\")\n",
    "os.makedirs(test_path_Groundtruth)\n",
    "test_path_Degraded2000 = os.path.join(test_path, \"Degraded\")\n",
    "os.makedirs(test_path_Degraded2000)\n",
    "test_path_H = os.path.join(test_path, \"H\")\n",
    "os.makedirs(test_path_H, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 0.5 identity\n",
      "0 th out of 1800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m np\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroundtruth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_Gr_tr_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(s, n, k, count)), signal)\n\u001b[0;32m     17\u001b[0m np\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDegraded\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_De_tr_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(s, n, k, count)), degraded_signal)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mH\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mH_tr_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msave\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Program Files\\Python39\\lib\\site-packages\\numpy\\lib\\npyio.py:522\u001b[0m, in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[0;32m    521\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n\u001b[1;32m--> 522\u001b[0m     \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfix_imports\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfix_imports\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python39\\lib\\site-packages\\numpy\\lib\\format.py:722\u001b[0m, in \u001b[0;36mwrite_array\u001b[1;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m--> 722\u001b[0m         \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    724\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39mnditer(\n\u001b[0;32m    725\u001b[0m                 array, flags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexternal_loop\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuffered\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzerosize_ok\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    726\u001b[0m                 buffersize\u001b[38;5;241m=\u001b[39mbuffersize, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # generate original_signal, noisy_signal, H for each parameter combination\n",
    "count = 0\n",
    "for s, n, k in hard_parameters:\n",
    "    print(s, n, k)\n",
    "    print(count, \"th out of\", len(hard_parameters) * num_samples)\n",
    "    for i in range(num_samples):\n",
    "        count += 1\n",
    "        if i < num_samples * 0.6:\n",
    "            path = training_path\n",
    "        elif i < num_samples * 0.8:\n",
    "            path = validation_path\n",
    "        else:\n",
    "            path = test_path\n",
    "        h = generate_kernel_h(length=50, type=k)\n",
    "        degraded_signal, signal, H = generate_synthetic_sparse_signal(length=length, sparsity=s, noise_level=n, h=h)\n",
    "        np.save(os.path.join(path, \"Groundtruth\", \"x_Gr_tr_{}_{}_{}_{}.npy\".format(s, n, k, count)), signal)\n",
    "        np.save(os.path.join(path, \"Degraded\", \"x_De_tr_{}_{}_{}_{}.npy\".format(s, n, k, count)), degraded_signal)\n",
    "        np.save(os.path.join(path, \"H\", \"H_tr_{}_{}_{}_{}.npy\".format(s, n, k, count)), H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
